{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import (img_to_array, \n",
    "                                       #load_img\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Define auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Read the images data on the disk to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_from_disk(path, npixel = (30, 40)):\n",
    "    \"\"\"\n",
    "        Reads the images data stored on the disk\n",
    "        \n",
    "        Arguments:\n",
    "            *path: the path of the disk directory containing the images data\n",
    "            *npixel: a tuple (image_width, image_height) in number of pixels\n",
    "        \n",
    "        Returns:\n",
    "            *data: a pandas dataframe where each example is one image \n",
    "    \"\"\"\n",
    "    #imgs = np.empty(shape = (1, npixel[1]*npixel[0]*3 + 1) )\n",
    "    imgs = pd.DataFrame(index = os.listdir(path), dtype = np.uint8,\n",
    "                        columns = np.arange(npixel[1]*npixel[0]*3))\n",
    "    #image_list = map(Image.open, glob('your/path/*.gif'))\n",
    "    assert os.path.exists(path)\n",
    "    print(\"Attention! Chargement de {} images! \\n\".format(len(os.listdir(path))))\n",
    "    print(\"Cette opération peut prendre du temps.\")\n",
    "    \n",
    "    for f in os.listdir(path):\n",
    "        #print(\"Ajout de l'image {} au dataset\".format(f))\n",
    "        img = Image.open(os.path.join(path,f))\n",
    "        img = img.resize((npixel[0],npixel[1]))\n",
    "        x = img_to_array(img)\n",
    "        x = x.astype(np.uint8)\n",
    "        x = x.reshape(1,-1)\n",
    "        if x.shape != (1, npixel[1]*npixel[0]*3):\n",
    "            #The image is black\n",
    "            x = np.zeros((1, npixel[1]*npixel[0]*3))\n",
    "            print(\"The image {} is black.\".format(f))\n",
    "        imgs.loc[f,:] = x\n",
    "    \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Reads the data stored as one unique csv table on the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv_data_from_disk(path):\n",
    "    \"\"\"\n",
    "        Reads a csv file stored on disk\n",
    "        \n",
    "        Arguments:\n",
    "            *path: the path of the csv data on the disk\n",
    "        \n",
    "        Returns:\n",
    "            *data: as a numpy array\n",
    "    \"\"\"\n",
    "    assert os.path.exists(path)\n",
    "    data = np.genfromtxt(path, delimiter=',')\n",
    "    return data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Writes a pandas dataframe on a disk under csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_data_csv(data, directory, name):\n",
    "    \"\"\"\n",
    "        Writes data to path\n",
    "        \n",
    "        Arguments: \n",
    "            *data: a pandas dataframe\n",
    "            *directory: the destination folder\n",
    "            *name: name under which we save the csv file\n",
    "        \n",
    "        Returns:\n",
    "            Nothing. \n",
    "    \"\"\"\n",
    "    data.to_csv(os.path.join(directory, name), sep = ',', index = True)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III - Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_path = \"/home/kevin/Desktop/OpenFoodFacts/OpenFoodFacts/data/images\"\n",
    "csv_directory = \"/home/kevin/Desktop/OpenFoodFacts/OpenFoodFacts/data/csv\"\n",
    "npixel = (30,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention! Chargement de 3145 images! \n",
      "\n",
      "Cette opération peut prendre du temps.\n",
      "The image 3245414172081front.4.400.jpg is black.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'write_data_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cd7272816b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_from_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Write pandas dataframe to csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwrite_data_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#Read data from csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'write_data_csv' is not defined"
     ]
    }
   ],
   "source": [
    "# Load images from disk to single pandas dataframe\n",
    "data = read_from_disk(images_path)\n",
    "#Write pandas dataframe to csv file\n",
    "write_data_csv(data, csv_directory, 'data.csv')\n",
    "#Read data from csv\n",
    "csv_path = os.path.join(csv_directory, 'data.csv')\n",
    "#data2 = read_csv_data_from_disk(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.ipynb   data.py\t\t read.ipynb  vgg16.ipynb\r\n",
      "data.pickle  deeplearning.ipynb  read.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' pandas dataframe using the highest protocol available.\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pkl_file = open('data.pickle', 'rb')\n",
    "\n",
    "data = pickle.load(pkl_file)\n",
    "pprint.pprint(data)\n",
    "\n",
    "pkl_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
